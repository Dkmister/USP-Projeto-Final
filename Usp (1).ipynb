{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "id": "4cF5KAcJyuBZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "class Modelo():\n",
        "    def __init__(self):\n",
        "        self = self\n",
        "\n",
        "    def CarregarDataset(self, path):\n",
        "        \"\"\"\n",
        "        Carrega o conjunto de dados a partir de um arquivo CSV.\n",
        "\n",
        "        Parâmetros:\n",
        "        - path (str): Caminho para o arquivo CSV contendo o dataset.\n",
        "\n",
        "        O dataset é carregado com as seguintes colunas: SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm e Species.\n",
        "        \"\"\"\n",
        "        names = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']\n",
        "        try:\n",
        "          self.df = pd.read_csv(path, names=names)\n",
        "          print(\"Dataset carregado com sucesso.\\n\")\n",
        "        except FileNotFoundError:\n",
        "          print(\"Arquivo não encontrado. Verifique o caminho especificado.\\n\")\n",
        "\n",
        "    def TratamentoDeDados(self):\n",
        "        \"\"\"\n",
        "        Realiza o pré-processamento dos dados carregados.\n",
        "\n",
        "        Sugestões para o tratamento dos dados:\n",
        "            * Utilize `self.df.head()` para visualizar as primeiras linhas e entender a estrutura.\n",
        "            * Verifique a presença de valores ausentes e faça o tratamento adequado.\n",
        "            * Considere remover colunas ou linhas que não são úteis para o treinamento do modelo.\n",
        "\n",
        "        Dicas adicionais:\n",
        "            * Explore gráficos e visualizações para obter insights sobre a distribuição dos dados.\n",
        "            * Certifique-se de que os dados estão limpos e prontos para serem usados no treinamento do modelo.\n",
        "        \"\"\"\n",
        "        # print(self.df.isnull().sum().sum()) # Sem valores NaN\n",
        "\n",
        "        # Transformando os valores em rótulos de 0 a 2\n",
        "        encoder = LabelEncoder()\n",
        "        obj_cols = ['Species']\n",
        "\n",
        "        values = self.df[obj_cols[0]].values\n",
        "        encoder.fit(values)\n",
        "        self.df[obj_cols[0]] = encoder.transform(values)\n",
        "\n",
        "\n",
        "    def Treinamento(self):\n",
        "        \"\"\"\n",
        "        Treina o modelo de machine learning.\n",
        "\n",
        "        Detalhes:\n",
        "            * Utilize a função `train_test_split` para dividir os dados em treinamento e teste.\n",
        "            * Escolha o modelo de machine learning que queira usar. Lembrando que não precisa ser SMV e Regressão linear.\n",
        "            * Experimente técnicas de validação cruzada (cross-validation) para melhorar a acurácia final.\n",
        "\n",
        "        Nota: Esta função deve ser ajustada conforme o modelo escolhido.\n",
        "        \"\"\"\n",
        "        self.X=self.df.drop('Species', axis=1)  # Features (todas as colunas exceto a de alvo)\n",
        "        self.y=self.df['Species']\n",
        "\n",
        "        self.X_train,self.X_test,self.y_train,self.y_test=train_test_split(self.X,self.y,test_size=0.2)\n",
        "\n",
        "\n",
        "    def Teste(self):\n",
        "        \"\"\"\n",
        "        Avalia o desempenho do modelo treinado nos dados de teste.\n",
        "\n",
        "        Esta função deve ser implementada para testar o modelo e calcular métricas de avaliação relevantes,\n",
        "        como acurácia, precisão, ou outras métricas apropriadas ao tipo de problema.\n",
        "        \"\"\"\n",
        "        logreg=LogisticRegression()\n",
        "        logreg.fit(self.X_train,self.y_train)\n",
        "\n",
        "\n",
        "        y_pred=logreg.predict(self.X_test)\n",
        "        print('Precisão de Regressão Logistica:')\n",
        "        print(metrics.accuracy_score(self.y_test,y_pred))\n",
        "        print('Score:')\n",
        "        print(logreg.score(self.X, self.y))\n",
        "\n",
        "        lreg=HistGradientBoostingClassifier()\n",
        "        lreg.fit(self.X_train,self.y_train)\n",
        "\n",
        "\n",
        "        y_pred=lreg.predict(self.X_test)\n",
        "        print('Precisão de Gradiente Booster:')\n",
        "        print(metrics.accuracy_score(self.y_test,y_pred))\n",
        "        print('Score:')\n",
        "        print(lreg.score(self.X, self.y))\n",
        "\n",
        "        knn=KNeighborsClassifier(n_neighbors=5)\n",
        "        knn.fit(self.X_train,self.y_train)\n",
        "\n",
        "        y_pred=knn.predict(self.X_test)\n",
        "        print('Precisao do KNN com 5 vizinhos')\n",
        "        print(metrics.accuracy_score(self.y_test,y_pred))\n",
        "        print('Score:')\n",
        "        print(knn.score(self.X, self.y))\n",
        "\n",
        "    def Train(self):\n",
        "        \"\"\"\n",
        "        Função principal para o fluxo de treinamento do modelo.\n",
        "\n",
        "        Este método encapsula as etapas de carregamento de dados, pré-processamento e treinamento do modelo.\n",
        "        Sua tarefa é garantir que os métodos `CarregarDataset`, `TratamentoDeDados` e `Treinamento` estejam implementados corretamente.\n",
        "\n",
        "        Notas:\n",
        "            * O dataset padrão é \"iris.data\", mas o caminho pode ser ajustado.\n",
        "            * Caso esteja executando fora do Colab e enfrente problemas com o path, use a biblioteca `os` para gerenciar caminhos de arquivos.\n",
        "        \"\"\"\n",
        "        self.CarregarDataset(\"iris.data\")  # Carrega o dataset especificado.\n",
        "\n",
        "        # Tratamento de dados opcional, pode ser comentado se não for necessário\n",
        "        self.TratamentoDeDados()\n",
        "\n",
        "        self.Treinamento()  # Executa o treinamento do modelo\n",
        "\n",
        "        self.Teste()\n",
        "\n",
        "# Lembre-se de instanciar as classes após definir suas funcionalidades\n",
        "# Recomenda-se criar ao menos dois modelos (e.g., Regressão Linear e SVM) para comparar o desempenho.\n",
        "# A biblioteca já importa LinearRegression e SVC, mas outras escolhas de modelo são permitidas."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Dkmister/USP-Projeto-Final/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cUzMfpszwya",
        "outputId": "e9a818ff-ecd5-4cbc-bb26-9bbff4455d99"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'USP-Projeto-Final'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 11 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (11/11), 16.70 KiB | 2.78 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd USP-Projeto-Final/\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZf11Uzpz25a",
        "outputId": "de29d01d-a678-40ce-9105-58f6a99abc20"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/USP-Projeto-Final/USP-Projeto-Final\n",
            "iris.data  LICENSE  main.py  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Modelo()\n",
        "\n"
      ],
      "metadata": {
        "id": "KTZWcSDry2_Q"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.Train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYsKdvvu0c7S",
        "outputId": "0b435f81-15b0-4853-c4e5-77fb580d8a67"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset carregado com sucesso.\n",
            "Precisão de Regressão Logistica:\n",
            "0.9666666666666667\n",
            "Score:\n",
            "0.96\n",
            "Precisão de Gradiente Booster:\n",
            "0.9666666666666667\n",
            "Score:\n",
            "0.9933333333333333\n",
            "Precisao do KNN com 5 vizinhos\n",
            "0.9666666666666667\n",
            "Score:\n",
            "0.9733333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusões\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Pode se perceber que todos métodos tem valores bem altos de predição, dependendo da iteração, um algoritmo é melhor que outro, mas não há uma diferença nítida.\n",
        "*   O método de Gradiente Booster teve uma eficácia menor que os outros métodos em algumas iterações.\n",
        "*   Parece que as vezes o KNN tem um overfit, conseguindo uma acurácia de 100%\n",
        "*   Foi necessário LabelEncoder para fazer a limpagem dos dados\n",
        "*   Não foi encontrado nenhum valor NaN no dataset.\n",
        "*   Acurácia varia muito dependendo do tamanho de treino.\n"
      ],
      "metadata": {
        "id": "rRIcuUJPGY-1"
      }
    }
  ]
}